# ğŸ½ï¸ Projeto de Big Data Analytics para Restaurantes

## ğŸ’¡ VisÃ£o Geral do Projeto

Este projeto de Big Data e Data Science tem como objetivo principal aplicar tÃ©cnicas de processamento de dados distribuÃ­dos para analisar o **desempenho operacional e comercial** de um restaurante.

O foco Ã© transformar dados de transaÃ§Ãµes (vendas de itens, horÃ¡rios, categorias) em *insights* acionÃ¡veis que possam otimizar o estoque, a precificaÃ§Ã£o e o planejamento de cardÃ¡pio do estabelecimento.

O projeto foi desenvolvido como requisito da disciplina [Nome da Disciplina] da [Nome da Universidade/Faculdade].

## ğŸ“Š Objetivo Principal

Analisar um volume significativo de transaÃ§Ãµes de vendas para identificar:
* PadrÃµes de consumo por horÃ¡rio e dia da semana.
* Itens mais vendidos e categorias mais lucrativas.
* OtimizaÃ§Ã£o de preÃ§os e avaliaÃ§Ã£o de desempenho de pratos.

## âš™ï¸ Tecnologias Utilizadas

A arquitetura do projeto Ã© construÃ­da em Python e foca em ferramentas de processamento de dados em diferentes escalas:

| Categoria | Ferramenta | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| **Processamento DistribuÃ­do (Big Data)** | **PySpark (Apache Spark)** | Utilizado para ingestÃ£o, transformaÃ§Ã£o (ETL) e anÃ¡lise de grandes volumes de dados de forma escalÃ¡vel e distribuÃ­da. |
| **ManipulaÃ§Ã£o de Dados (Local)** | **Pandas** | Utilizado para prototipagem inicial e geraÃ§Ã£o do *dataset* simulado. |
| **Linguagem de ProgramaÃ§Ã£o** | **Python** | Linguagem principal de desenvolvimento. |
| **Gerenciamento de Ambiente** | **Ambiente Virtual (`venv`)** | Garante o isolamento e a reprodutibilidade das dependÃªncias do projeto. |

## ğŸ“‚ Estrutura do Projeto

O projeto segue a seguinte organizaÃ§Ã£o modular:

Big_Data_Project/ | â”œâ”€â”€ data/ â”‚ â”œâ”€â”€ raw/ # Dados de vendas brutos (incluindo o CSV simulado) â”‚ â””â”€â”€ processed/ # Dados limpos e transformados pelo PySpark | â”œâ”€â”€ src/ # CÃ³digo-fonte Python principal â”‚ â”œâ”€â”€ data_generator.py # Script de geraÃ§Ã£o dos dados simulados (Pandas) â”‚ â””â”€â”€ etl_pyspark.py # Script de processamento ETL e AnÃ¡lise (PySpark) | â”œâ”€â”€ notebooks/ # (Opcional) Jupyter Notebooks para exploraÃ§Ã£o de dados â”œâ”€â”€ reports/ # Resultados de anÃ¡lise e visualizaÃ§Ãµes â””â”€â”€ requirements.txt # Lista de dependÃªncias Python

## ğŸš€ Como Executar

1.  **Clone o repositÃ³rio:** `git clone https://docs.github.com/pt/migrations/importing-source-code/using-the-command-line-to-import-source-code/adding-locally-hosted-code-to-github`
2.  **Crie e Ative o Ambiente Virtual:**
    ```bash
    python -m venv venv
    source venv/Scripts/activate  # Para Git Bash/Linux
    # OU: venv\Scripts\activate   # Para CMD/PowerShell
    ```
3.  **Instale as DependÃªncias:** `pip install -r requirements.txt`
4.  **Gere os Dados Simulados:** `python src/data_generator.py`
5.  **Execute o Processamento PySpark:** `python src/etl_pyspark.py`